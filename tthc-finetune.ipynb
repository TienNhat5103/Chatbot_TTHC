{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12869259,"sourceType":"datasetVersion","datasetId":8140591},{"sourceId":12872350,"sourceType":"datasetVersion","datasetId":8142802}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install -q accelerate peft bitsandbytes transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T03:13:07.055815Z","iopub.execute_input":"2025-08-26T03:13:07.056047Z","iopub.status.idle":"2025-08-26T03:14:35.363099Z","shell.execute_reply.started":"2025-08-26T03:13:07.056024Z","shell.execute_reply":"2025-08-26T03:14:35.362410Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%%capture\n!pip install langchain faiss-cpu sentence-transformers\n!pip install langchain_community","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T03:14:35.366731Z","iopub.execute_input":"2025-08-26T03:14:35.366980Z","iopub.status.idle":"2025-08-26T03:14:35.775047Z","shell.execute_reply.started":"2025-08-26T03:14:35.366946Z","shell.execute_reply":"2025-08-26T03:14:35.774295Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83974addc66145dc996904e3d71c3ba1"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-26T03:14:35.775735Z","iopub.execute_input":"2025-08-26T03:14:35.775915Z","iopub.status.idle":"2025-08-26T03:14:36.116640Z","shell.execute_reply.started":"2025-08-26T03:14:35.775900Z","shell.execute_reply":"2025-08-26T03:14:36.115853Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/public-service/train_phogpt.jsonl\n/kaggle/input/public-service/val_phogpt.jsonl\n/kaggle/input/public-service/test_phogpt.jsonl\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())\nprint(torch.cuda.get_device_name(0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T03:16:46.221631Z","iopub.execute_input":"2025-08-26T03:16:46.221892Z","iopub.status.idle":"2025-08-26T03:16:51.526621Z","shell.execute_reply.started":"2025-08-26T03:16:46.221871Z","shell.execute_reply":"2025-08-26T03:16:51.525952Z"}},"outputs":[{"name":"stdout","text":"True\nTesla T4\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset('json', data_files={\n    \"train\": \"/kaggle/input/public-service/train_phogpt.jsonl\",\n    \"validation\": \"/kaggle/input/public-service/val_phogpt.jsonl\",\n    \"test\": \"/kaggle/input/public-service/test_phogpt.jsonl\"\n}, split=None)\n\ntrain_data = dataset[\"train\"]\nval_data = dataset[\"validation\"]\ntest_data = dataset[\"test\"]\n\nprint(\"Train size:\", len(train_data))\nprint(\"Validation size:\", len(val_data))\nprint(\"Test size:\", len(test_data))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T13:22:46.842022Z","iopub.execute_input":"2025-08-26T13:22:46.842359Z","iopub.status.idle":"2025-08-26T13:22:52.825883Z","shell.execute_reply.started":"2025-08-26T13:22:46.842328Z","shell.execute_reply":"2025-08-26T13:22:52.824467Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f602ed09849b4efdafe0438ddcfd30d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9de94d1b50d4424b83d1cbb6b28e4685"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"616e9c56cbc64d40a30157e35584135b"}},"metadata":{}},{"name":"stdout","text":"Train size: 3517\nValidation size: 100\nTest size: 100\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"print(train_data[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T13:22:55.806494Z","iopub.execute_input":"2025-08-26T13:22:55.806978Z","iopub.status.idle":"2025-08-26T13:22:55.814364Z","shell.execute_reply.started":"2025-08-26T13:22:55.806942Z","shell.execute_reply":"2025-08-26T13:22:55.813020Z"}},"outputs":[{"name":"stdout","text":"{'instruction': 'Bạn là trợ lý dịch vụ công, trả lời ngắn gọn, chính xác.', 'input': 'Trung tâm hòa giải thương mại tự chấm dứt hoạt động thì cần thực hiện thủ tục gì tại Sở Tư pháp?', 'output': 'Theo quy định tại Điều 31 Nghị định số 22/2017/NĐ-CP ngày 24/02/2017 của Chính phủ về hòa giải thương mại thì Trung tâm hòa giải thương mại muốn tự chấm dứt hoạt động thì chậm nhất 30 ngày trước ngày chấm dứt hoạt động, Trung tâm hòa giải thương mại thông báo bằng văn bản về việc chấm dứt hoạt động cho Sở Tư pháp tỉnh, thành phố trực thuộc Trung ương nơi Trung tâm đăng ký hoạt động. Trong thời hạn 60 ngày, kể từ ngày quyết định chấm dứt hoạt động, Trung tâm hòa giải thương mại thanh toán xong các khoản nợ, nghĩa vụ tài sản khác, thanh lý các hợp đồng, hoàn tất các vụ việc đã nhận, trừ trường hợp có thỏa thuận khác.'}\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling, BitsAndBytesConfig\n\ndef print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T03:16:53.359686Z","iopub.execute_input":"2025-08-26T03:16:53.360121Z","iopub.status.idle":"2025-08-26T03:17:25.156020Z","shell.execute_reply.started":"2025-08-26T03:16:53.360102Z","shell.execute_reply":"2025-08-26T03:17:25.155283Z"}},"outputs":[{"name":"stderr","text":"2025-08-26 03:17:06.698294: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756178227.077098      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756178227.186419      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"model_name = 'Viet-Mistral/Vistral-7B-Chat'\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit= True,\n    bnb_4bit_quant_type= \"nf4\",\n    bnb_4bit_compute_dtype= torch.float16,\n    bnb_4bit_use_double_quant= False,\n)\nmodel = AutoModelForCausalLM.from_pretrained(\n        model_name,\n        quantization_config=bnb_config,\n        torch_dtype=torch.float16,\n        device_map={\"\": 0},\n        trust_remote_code=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T03:17:25.157644Z","iopub.execute_input":"2025-08-26T03:17:25.158204Z","iopub.status.idle":"2025-08-26T03:20:26.574748Z","shell.execute_reply.started":"2025-08-26T03:17:25.158151Z","shell.execute_reply":"2025-08-26T03:20:26.574073Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c88e84017eb43008221df8004a265a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dc69a9f57914756ba48352e9cc309c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0daad39071554ad684ed2d255be5ec80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/10.0G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bb4f0413be94c31a895c5040d3a78b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.59G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11ede10f15b140edbc72e2e1caf84ae2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"390ae18492344c9b9e723708d9d25554"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/133 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33c09ff432634e35b45232759da87f96"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\ntokenizer.padding_side = 'right'\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.add_eos_token = True\ntokenizer.bos_token, tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T03:20:26.575528Z","iopub.execute_input":"2025-08-26T03:20:26.575727Z","iopub.status.idle":"2025-08-26T03:20:28.454679Z","shell.execute_reply.started":"2025-08-26T03:20:26.575711Z","shell.execute_reply":"2025-08-26T03:20:28.454007Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.52k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fdf272fc72441f784489223fa30365e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/597k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64aea5d79f664c4798cf21d1a647f35a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.15M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"595bf7c054794308bc9be0974e696fb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16f1799be611439e9a036b97d297179a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/169 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8056aa515c04c9492a6f3a503f01019"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"('<s>', '</s>')"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def merge_columns(examples):\n    return {\n        \"text\": [\n            f\"{i} {inp} {outp}\"\n            for i, inp, outp in zip(examples[\"instruction\"], examples[\"input\"], examples[\"output\"])\n        ]\n    }\n\ndef tokenize_function(examples):\n    enc = tokenizer(\n        examples[\"text\"],\n        truncation=True,\n        max_length=512,\n        padding=\"max_length\"\n    )\n    enc[\"labels\"] = [l if l != tokenizer.pad_token_id else -100 for l in enc[\"input_ids\"]]\n    return enc\n\n\ntrain_data = train_data.map(merge_columns, batched=True)\nval_data = val_data.map(merge_columns, batched=True)\ntest_data = test_data.map(merge_columns, batched=True)\n\ntrain_data = train_data.map(tokenize_function, batched=True)\nval_data = val_data.map(tokenize_function, batched=True)\ntest_data = test_data.map(tokenize_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T03:20:28.455547Z","iopub.execute_input":"2025-08-26T03:20:28.455818Z","iopub.status.idle":"2025-08-26T03:20:30.521279Z","shell.execute_reply.started":"2025-08-26T03:20:28.455795Z","shell.execute_reply":"2025-08-26T03:20:30.520446Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3517 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccfcf9c8b0654fcea92bd22ac5afbe74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8464d4064a744434bac342f9ee5d23c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4289bdf6b39a415f92bc05b10b8f9874"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3517 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e752e9ab628143f1b9ddbb439890c790"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3f006d72fee429bb80b4169c0294a29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b094a710fb624134be07d05e6f2e6435"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"model = prepare_model_for_kbit_training(model)\npeft_config = LoraConfig(\n    lora_alpha=8,\n    lora_dropout=0.05,\n    r=32,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"]\n)\nmodel = get_peft_model(model, peft_config)\nprint_trainable_parameters(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T03:20:30.522083Z","iopub.execute_input":"2025-08-26T03:20:30.522350Z","iopub.status.idle":"2025-08-26T03:20:31.585563Z","shell.execute_reply.started":"2025-08-26T03:20:30.522326Z","shell.execute_reply":"2025-08-26T03:20:31.584785Z"}},"outputs":[{"name":"stdout","text":"trainable params: 46137344 || all params: 3850383360 || trainable%: 1.1982532565276824\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./Vistral-finetuned\",\n    per_device_train_batch_size=2,\n    gradient_accumulation_steps=4,\n    num_train_epochs=1,\n    learning_rate=2e-4,\n    fp16=True,\n    optim=\"paged_adamw_8bit\",\n    gradient_checkpointing=False,\n    save_strategy=\"epoch\",\n    save_total_limit=3,\n    logging_dir=\"./logs\",\n    logging_steps=50,\n    report_to=\"none\",\n    warmup_ratio=0.03,\n    weight_decay=0.001,\n    lr_scheduler_type=\"constant\"\n)\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T03:28:02.475557Z","iopub.execute_input":"2025-08-26T03:28:02.475857Z","iopub.status.idle":"2025-08-26T03:28:02.607904Z","shell.execute_reply.started":"2025-08-26T03:28:02.475835Z","shell.execute_reply":"2025-08-26T03:28:02.607142Z"}},"outputs":[{"name":"stderr","text":"No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"trainer.train()\ntrainer.save_model(\"./Vistral-finetuned-final\")\ntokenizer.save_pretrained(\"./Vistral-finetuned-final\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T03:28:06.068423Z","iopub.execute_input":"2025-08-26T03:28:06.068698Z","iopub.status.idle":"2025-08-26T04:56:11.985276Z","shell.execute_reply.started":"2025-08-26T03:28:06.068677Z","shell.execute_reply":"2025-08-26T04:56:11.984658Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='220' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [220/220 1:27:39, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>2.274000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>2.250000</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>2.381800</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>2.347200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"('./Vistral-finetuned-final/tokenizer_config.json',\n './Vistral-finetuned-final/special_tokens_map.json',\n './Vistral-finetuned-final/chat_template.jinja',\n './Vistral-finetuned-final/tokenizer.model',\n './Vistral-finetuned-final/added_tokens.json',\n './Vistral-finetuned-final/tokenizer.json')"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"!zip -r Vistral-finetuned-final.zip ./Vistral-finetuned-final","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T04:57:59.660648Z","iopub.execute_input":"2025-08-26T04:57:59.661020Z","iopub.status.idle":"2025-08-26T04:58:05.761210Z","shell.execute_reply.started":"2025-08-26T04:57:59.660988Z","shell.execute_reply":"2025-08-26T04:58:05.760247Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"  adding: Vistral-finetuned-final/ (stored 0%)\n  adding: Vistral-finetuned-final/training_args.bin (deflated 51%)\n  adding: Vistral-finetuned-final/special_tokens_map.json (deflated 70%)\n  adding: Vistral-finetuned-final/chat_template.jinja (deflated 61%)\n  adding: Vistral-finetuned-final/tokenizer.model (deflated 58%)\n  adding: Vistral-finetuned-final/added_tokens.json (deflated 42%)\n  adding: Vistral-finetuned-final/tokenizer.json (deflated 85%)\n  adding: Vistral-finetuned-final/tokenizer_config.json (deflated 78%)\n  adding: Vistral-finetuned-final/README.md (deflated 66%)\n  adding: Vistral-finetuned-final/adapter_config.json (deflated 56%)\n  adding: Vistral-finetuned-final/adapter_model.safetensors (deflated 59%)\n","output_type":"stream"}],"execution_count":13}]}